import type { Competence } from "./competence";
import { Logger } from "./logger";

/**
 * Interface representing a token generated by the lexer.
 * @template P - A boolean indicating if the token contains an inner value.
 */
export interface Token<P extends true | false> {
	/** The competence that matched this token. */
	competence: Competence;
	/** The full matched string. */
	total: P extends true ? `${string}[${string}]` : string;
	/** The inner content of the token if it exists, otherwise null. */
	inside: P extends true ? string : null;
	/** The regular expression match array for this token. */
	match: RegExpExecArray;
	/** The name of the token. */
	name: string;
}

/**
 * Interface representing a support token used internally in the lexer.
 */
export interface SupportToken {
	/** The regular expression match array for the support token. */
	match: RegExpExecArray & ["[" | "]"];
	/** The depth level of nested brackets. */
	depth: number;
}

/**
 * Lexer class responsible for tokenizing code into a series of tokens based on competences.
 */
export class Lexer {
	/** Logger instance for logging messages. */
	protected readonly logger = new Logger();
	/** Map of competences used by the lexer to tokenize code. */
	public readonly competences = new Map<string, Competence>();

	/**
	 * Gets the combined regular expression pattern for all competences.
	 * @returns The combined regular expression pattern.
	 */
	public get pattern(): RegExp {
		return new RegExp([...this.competences.values()].map((c) => c.pattern.source).join("|"), "gm");
	}

	/**
	 * Tokenizes the given code into a series of tokens based on defined competences.
	 * @param code - The code to tokenize.
	 * @returns An array of tokens generated from the code.
	 */
	public tokenize(code: string): Token<boolean>[] {
		const tokens: Token<boolean>[] = [];
		const regex = this.pattern;
		let min_index = 0;

		for (let match = regex.exec(code), i = 0; match !== null; match = regex.exec(code), i++) {
			const competence = [...this.competences.values()].find((c) => c.pattern.test(match[0]));

			if (!competence) {
				this.logger.warn("LEXER", `No competition was found for "${match[0]}".`);
				continue;
			}

			const token: Token<boolean> = {
				competence,
				total: match[0],
				inside: null,
				name: match[0],
				match,
			};

			const after = code.slice(match.index + match[0].length);
			if (after && after[0] === "[") {
				token.inside = "";
				let depth = 0;
				for (const char of after.slice(1)) {
					if (char === "]" && depth === 0) break;
					if (char === "[") depth++;
					if (char === "]") depth--;
					token.inside += char;
				}
			}

			token.match.index += min_index;
			token.total += `[${token.inside}]`;
			tokens.push(token);
			min_index += token.total.length - 1;
			code = code.replace(token.total, `<PROCESSED:${Date.now()}>`);
		}

		return tokens;
	}
}
