import type { Competence } from "./competence";
import { Logger } from "./logger";

/**
 * Interface representing a token generated by the lexer.
 * @template P - A boolean indicating if the token contains an inner value.
 */
export interface Token<P extends true | false> {
	/** The competence that matched this token. */
	competence: Competence;
	/** The full matched string. */
	total: P extends true ? `${string}[${string}]` : string;
	/** The inner content of the token if it exists, otherwise null. */
	inside: P extends true ? string : null;
	/** The regular expression match array for this token. */
	match: RegExpExecArray;
	/** The name of the token. */
	name: string;
}

/**
 * Lexer class responsible for tokenizing code into a series of tokens based on competences.
 */
export class Lexer {
	/** Logger instance for logging messages. */
	protected readonly logger = new Logger();
	/** Map of competences used by the lexer to tokenize code. */
	public readonly competences = new Map<string, Competence>();

	/**
	 * Gets the combined regular expression pattern for all competences.
	 * @returns The combined regular expression pattern.
	 */
	public get pattern(): RegExp {
		return new RegExp(
			[...this.competences.values()].map((c) => c.patterns.foremost.source).join("|"),
			"gm",
		);
	}

	/**
	 * Tokenizes the given code into a series of tokens based on defined competences.
	 * @param code - The code to tokenize.
	 * @yields An array of tokens generated from the code.
	 */
	public *tokenize(code: string): Generator<Token<boolean>> {
		const regex = this.pattern;
		let minIndex = 0;

		const competencesArray = [...this.competences.values()];

		for (let match = regex.exec(code); match !== null; match = regex.exec(code)) {
			const competence = competencesArray.find((c) => c.patterns.foremost.test(match[0]));

			if (!competence) {
				this.logger.warn("LEXER", `No competence found for "${match[0]}".`);
				continue;
			}

			const token: Token<boolean> = {
				competence,
				total: match[0],
				inside: null,
				name: match[0],
				match,
			};

			let opener = "";
			let closer = "";

			if (competence.patterns.opener) {
				const after = code.slice(match.index + match[0].length);
				if (after && competence.patterns.opener.test(after[0])) {
					opener = after[0];
					token.inside = "";
					let depth = 0;

					for (let i = 1; i < after.length; i++) {
						const char = after[i];
						if (competence.patterns.closer?.test(char) && depth === 0) {
							closer = char;
							break;
						}
						if (competence.patterns.opener.test(char)) depth++;
						if (competence.patterns.closer?.test(char)) depth--;
						if (
							competence.patterns.inside === undefined ||
							competence.patterns.inside?.test(char)
						) {
							token.inside += char;
						} else if (!competence.patterns.unstoppable) {
							break;
						}
					}
				}
			}

			token.match.index += minIndex;
			token.total += opener + (token.inside ?? "") + closer;
			yield token;
			minIndex += token.total.length - 1;
			code = code.replace(
				token.total,
				`PCSTN?${(Math.random() * 10e16 + Date.now()).toString(32)}`,
			);
		}
	}
}
